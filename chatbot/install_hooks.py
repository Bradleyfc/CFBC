#!/usr/bin/env python
"""
Hooks de instalaci√≥n para el chatbot
Se ejecutan autom√°ticamente despu√©s de instalar las dependencias
"""

import os
import sys
import logging
import subprocess
from pathlib import Path

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(message)s'
)
logger = logging.getLogger(__name__)


def check_dependencies():
    """Verifica que las dependencias del chatbot est√©n instaladas"""
    required_packages = [
        'sentence_transformers',
        'transformers', 
        'torch',
        'faiss',
        'numpy'
    ]
    
    missing = []
    for package in required_packages:
        try:
            __import__(package.replace('-', '_'))
        except ImportError:
            missing.append(package)
    
    return missing


def download_models():
    """Descarga los modelos necesarios para el chatbot con optimizaciones"""
    
    logger.info("ü§ñ Iniciando descarga optimizada de modelos del chatbot...")
    logger.info("=" * 60)
    
    # Verificar dependencias
    missing = check_dependencies()
    if missing:
        logger.error(f"‚ùå Dependencias faltantes: {', '.join(missing)}")
        logger.info("üí° Ejecuta: pip install -r requirements.txt")
        return False
    
    try:
        # Configurar Django si es necesario
        if 'DJANGO_SETTINGS_MODULE' not in os.environ:
            os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'cfbc.settings')
        
        # Importar Django
        import django
        django.setup()
        
        # Usar descargador optimizado
        from chatbot.services.model_downloader import model_downloader
        
        # 1. Modelo de embeddings
        embedding_model = 'paraphrase-multilingual-MiniLM-L12-v2'
        logger.info(f"üì• Verificando modelo de embeddings: {embedding_model}")
        
        if model_downloader.check_model_cached(embedding_model):
            logger.info("   ‚úÖ Modelo de embeddings ya disponible")
        else:
            logger.info("   üì¶ Descargando modelo de embeddings (~470 MB)...")
            if model_downloader.download_model_smart(embedding_model):
                logger.info("   ‚úÖ Modelo de embeddings descargado")
            else:
                logger.warning("   ‚ö†Ô∏è  Error descargando embeddings, se descargar√° al usar")
        
        # Verificar que funcione
        try:
            from chatbot.services.semantic_search import SemanticSearchService
            search_service = SemanticSearchService()
            test_embedding = search_service.generate_embedding("prueba")
            logger.info(f"   ‚úÖ Embeddings funcionando (dimensi√≥n: {len(test_embedding)})")
        except Exception as e:
            logger.warning(f"   ‚ö†Ô∏è  Error verificando embeddings: {e}")
        
        # 2. Modelo LLM (opcional y m√°s lento)
        from chatbot.config import LLM_ENABLED, LLM_MODEL
        
        if LLM_ENABLED:
            logger.info(f"üì• Verificando modelo LLM: {LLM_MODEL}")
            
            if model_downloader.check_model_cached(LLM_MODEL):
                logger.info("   ‚úÖ Modelo LLM ya disponible")
            else:
                logger.info("   üì¶ Descargando modelo LLM (~308 MB)...")
                logger.info("   ‚è≥ Esta descarga puede tomar varios minutos...")
                
                if model_downloader.download_model_smart(LLM_MODEL):
                    logger.info("   ‚úÖ Modelo LLM descargado")
                else:
                    logger.warning("   ‚ö†Ô∏è  Error descargando LLM, se descargar√° al usar")
            
            # Verificar LLM
            try:
                from chatbot.services.llm_generator import LLMGeneratorService
                llm_service = LLMGeneratorService()
                if llm_service.is_available():
                    logger.info("   ‚úÖ LLM funcionando correctamente")
                else:
                    logger.info("   ‚ÑπÔ∏è  LLM no disponible (normal si est√° deshabilitado)")
            except Exception as e:
                logger.warning(f"   ‚ö†Ô∏è  Error verificando LLM: {e}")
        else:
            logger.info("‚ÑπÔ∏è  Modelo LLM deshabilitado en configuraci√≥n")
            logger.info("   üí° Para habilitarlo: LLM_ENABLED=true en variables de entorno")
        
        logger.info("üéâ ¬°Descarga de modelos completada!")
        logger.info("üìç Ubicaci√≥n: ~/.cache/huggingface/")
        logger.info("üíæ Espacio utilizado: ~470-800 MB (seg√∫n configuraci√≥n)")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error descargando modelos: {e}")
        logger.info("üîß Soluciones:")
        logger.info("   1. Verificar conexi√≥n a internet")
        logger.info("   2. Verificar espacio en disco (necesario: 1GB)")
        logger.info("   3. Ejecutar manualmente: python manage.py download_models")
        logger.info("   4. Deshabilitar LLM: LLM_ENABLED=false")
        return False


def post_install_setup():
    """Configuraci√≥n completa post-instalaci√≥n"""
    
    logger.info("üöÄ Configuraci√≥n post-instalaci√≥n del chatbot")
    logger.info("=" * 50)
    
    # 1. Descargar modelos
    if not download_models():
        logger.warning("‚ö†Ô∏è  Modelos no descargados, se descargar√°n al usar el chatbot")
    
    # 2. Verificar estructura de directorios
    logger.info("üìÅ Verificando estructura de directorios...")
    
    base_dir = Path(__file__).parent.parent
    required_dirs = [
        base_dir / 'chatbot_data',
        base_dir / 'chatbot_data' / 'faiss_index',
        base_dir / 'chatbot_data' / 'models'
    ]
    
    for dir_path in required_dirs:
        dir_path.mkdir(parents=True, exist_ok=True)
        logger.info(f"   ‚úÖ {dir_path.name}")
    
    # 3. Informaci√≥n final
    logger.info("üéØ Pr√≥ximos pasos:")
    logger.info("   1. python manage.py migrate")
    logger.info("   2. python manage.py loaddata chatbot/fixtures/*.json")
    logger.info("   3. python manage.py rebuild_index")
    logger.info("   4. python manage.py runserver")
    
    logger.info("‚úÖ Configuraci√≥n post-instalaci√≥n completada")


if __name__ == "__main__":
    post_install_setup()