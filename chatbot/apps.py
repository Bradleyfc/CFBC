from django.apps import AppConfig
import os
import logging

logger = logging.getLogger(__name__)


class ChatbotConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'chatbot'
    
    def ready(self):
        """Import signals when app is ready"""
        # import chatbot.signals  # noqa  # Temporarily disabled
        
        # Descargar modelos autom√°ticamente si no existen
        self._ensure_models_downloaded()
    
    def _ensure_models_downloaded(self):
        """Descarga autom√°ticamente los modelos si no est√°n disponibles"""
        
        # Solo ejecutar en el proceso principal (no en workers)
        if os.environ.get('RUN_MAIN') == 'true' or 'runserver' not in os.sys.argv:
            return
            
        try:
            # Verificar si los modelos ya est√°n descargados
            from chatbot.services.semantic_search import SemanticSearchService
            from chatbot.services.llm_generator import LLMGeneratorService
            
            # Intentar cargar los servicios (esto descarga los modelos si no existen)
            logger.info("ü§ñ Verificando modelos del chatbot...")
            
            # Verificar modelo de embeddings
            try:
                search_service = SemanticSearchService()
                test_embedding = search_service.generate_embedding("test")
                logger.info("‚úÖ Modelo de embeddings disponible")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Modelo de embeddings no disponible: {e}")
                self._download_models_async()
                return
            
            # Verificar modelo LLM
            try:
                llm_service = LLMGeneratorService()
                if llm_service.is_available():
                    logger.info("‚úÖ Modelo LLM disponible")
                else:
                    logger.info("‚ÑπÔ∏è  Modelo LLM deshabilitado en configuraci√≥n")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Modelo LLM no disponible: {e}")
                self._download_models_async()
                return
                
            logger.info("üéâ Todos los modelos del chatbot est√°n listos")
            
        except Exception as e:
            logger.error(f"‚ùå Error verificando modelos: {e}")
            self._download_models_async()
    
    def _download_models_async(self):
        """Descarga los modelos en segundo plano"""
        import threading
        
        def download_worker():
            try:
                logger.info("üì• Descargando modelos del chatbot en segundo plano...")
                logger.info("   Esto puede tomar varios minutos la primera vez...")
                
                # Importar y usar los servicios (esto fuerza la descarga)
                from chatbot.services.semantic_search import SemanticSearchService
                from chatbot.services.llm_generator import LLMGeneratorService
                
                # Descargar modelo de embeddings
                logger.info("üì• Descargando modelo de embeddings (~470 MB)...")
                search_service = SemanticSearchService()
                search_service.generate_embedding("test")
                logger.info("‚úÖ Modelo de embeddings descargado")
                
                # Descargar modelo LLM
                logger.info("üì• Descargando modelo LLM (~308 MB)...")
                llm_service = LLMGeneratorService()
                if llm_service.is_available():
                    logger.info("‚úÖ Modelo LLM descargado")
                
                logger.info("üéâ ¬°Descarga de modelos completada!")
                
            except Exception as e:
                logger.error(f"‚ùå Error descargando modelos: {e}")
                logger.info("üí° Puedes descargarlos manualmente con: python manage.py download_models")
        
        # Ejecutar descarga en hilo separado para no bloquear Django
        thread = threading.Thread(target=download_worker, daemon=True)
        thread.start()
